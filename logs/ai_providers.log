2025-09-04 19:47:56,944 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=auto analyze=True
2025-09-04 19:48:07,024 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 19:48:23,703 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-04 20:15:53,515 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=do analyze=True
2025-09-04 20:15:58,935 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:16:00,441 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:16:02,506 [INFO] dash.ai: news.summary: asset=BTC model_pref=do items=1
2025-09-04 20:16:06,556 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:31:18,249 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-04 20:31:23,480 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:31:28,627 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-04 20:34:46,975 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-04 20:34:52,324 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:34:58,502 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-04 20:35:23,506 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-04 20:35:28,688 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:35:28,725 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=15 model_pref=auto analyze=True
2025-09-04 20:35:33,274 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-04 20:35:33,680 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=15 model_pref=do analyze=True
2025-09-04 20:35:39,707 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=15 model_pref=do analyze=True
2025-09-04 20:35:42,118 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:35:43,570 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:35:44,604 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:45,774 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:46,279 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:48,018 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:48,194 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:49,547 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:49,802 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:50,860 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:51,436 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:35:51,648 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:52,241 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:53,136 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:53,342 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:53,554 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:54,920 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:55,006 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:55,305 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:56,394 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:56,650 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:57,321 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:58,203 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:59,048 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:59,067 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:35:59,730 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:00,469 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:00,734 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:01,155 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:01,731 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:02,172 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:02,677 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:03,159 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:03,674 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:04,078 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:04,691 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:04,935 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:05,523 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:06,130 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:06,324 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:06,940 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:07,485 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:07,735 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:08,918 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:10,152 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:11,597 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:13,010 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:14,567 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:27,947 [INFO] dash.ai: news.summary: asset=BTC model_pref=do items=15
2025-09-04 20:36:31,953 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=15
2025-09-04 20:36:33,725 [INFO] dash.ai: news.summary: asset=BTC model_pref=do items=15
2025-09-04 20:36:37,278 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:39,979 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:36:44,707 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:21,796 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=do analyze=True
2025-09-04 20:37:23,982 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=auto analyze=True
2025-09-04 20:37:25,927 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=gemini analyze=True
2025-09-04 20:37:29,610 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=gemini analyze=True
2025-09-04 20:37:31,661 [INFO] dash.ai: news.fetch: asset=BTC days=14 max=30 model_pref=gemini analyze=True
2025-09-04 20:37:32,187 [INFO] dash.ai: news.fetch: asset=BTC days=14 max=30 model_pref=gemini analyze=True
2025-09-04 20:37:34,079 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:37:35,917 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:37:36,015 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:37,727 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:37,765 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:39,161 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:39,462 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:41,036 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:41,108 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:37:41,108 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:41,788 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:37:42,546 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:42,772 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:43,104 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:43,944 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:37:44,141 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:44,242 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:44,245 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:44,775 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:45,377 [INFO] dash.ai: news.fetch: providers use_do=True use_hf=False have_keys do=True hf=True
2025-09-04 20:37:45,593 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:45,729 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:46,045 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:46,070 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:46,203 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:47,302 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:47,307 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:47,362 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:47,565 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:47,611 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:47,643 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:48,831 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:49,103 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:49,152 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:49,184 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:49,273 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:49,669 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:50,298 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:50,588 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:50,603 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:50,911 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:51,016 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:51,120 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:51,577 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:52,109 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:52,215 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:52,541 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:52,563 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:52,678 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:52,831 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:53,386 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:53,661 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:53,933 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:54,115 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:54,249 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:54,259 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:55,007 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:55,259 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:55,553 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:55,734 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:55,752 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:56,464 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:56,972 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:57,005 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:57,024 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:57,227 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:57,548 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:58,411 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:58,527 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:58,552 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:58,647 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:58,836 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:59,149 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:37:59,919 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:00,102 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:00,177 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:00,223 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:00,224 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:00,671 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:01,419 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:01,533 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:01,717 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:01,788 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:01,825 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:02,116 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:02,705 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:02,901 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:03,140 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:03,294 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:03,380 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:03,458 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:04,186 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:04,287 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:04,840 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:04,891 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:05,012 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:05,694 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:05,766 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:05,766 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:06,575 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:06,575 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:06,602 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:07,189 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:07,215 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:07,234 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:08,013 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:08,193 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:08,196 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:08,564 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:08,634 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:08,773 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:09,508 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:09,511 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:09,574 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:10,042 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:10,114 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:10,232 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:10,804 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:10,989 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:11,163 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:11,720 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:11,810 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:11,863 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:12,427 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:12,501 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:12,659 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:13,027 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:13,102 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:13,160 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:13,807 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:13,821 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:13,910 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:14,635 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:14,753 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:14,811 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:15,173 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:15,240 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:15,285 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:15,868 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:16,070 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:16,148 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:16,543 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:16,648 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:16,789 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:17,341 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:17,596 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:17,661 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:17,948 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:18,072 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:18,568 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:18,580 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:18,927 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:18,979 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:19,293 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:19,544 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:19,772 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:20,091 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:20,275 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:20,652 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:20,750 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:20,872 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:21,150 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:21,581 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:21,765 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:21,937 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:22,015 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:22,294 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:22,958 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:23,301 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:23,448 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:23,836 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:24,203 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:24,596 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:24,748 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:25,279 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:25,783 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:26,006 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:26,124 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:26,491 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:26,910 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:27,372 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:27,593 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:27,593 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:29,047 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:30,303 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:31,719 [INFO] dash.ai: news.HF/DO: DO POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:38:58,867 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=30
2025-09-04 20:39:00,545 [INFO] dash.ai: news.summary: asset=BTC model_pref=do items=30
2025-09-04 20:39:01,629 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=30
2025-09-04 20:39:07,624 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=30
2025-09-04 20:39:08,069 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=30
2025-09-04 20:39:08,240 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:39:08,950 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=30
2025-09-04 20:39:16,696 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:45:43,535 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=gemini analyze=True
2025-09-04 20:45:53,331 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:46:19,067 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=10
2025-09-04 20:47:02,649 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=10 model_pref=gemini analyze=True
2025-09-04 20:47:09,668 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:47:20,934 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=10
2025-09-04 20:47:44,603 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=10 model_pref=gemini analyze=True
2025-09-04 20:47:52,942 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:48:09,342 [INFO] dash.ai: news.summary: asset=NVDA model_pref=gemini items=10
2025-09-04 20:51:45,676 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=20 model_pref=auto analyze=True
2025-09-04 20:51:53,663 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:52:29,799 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=15 model_pref=auto analyze=True
2025-09-04 20:52:38,150 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 20:53:05,184 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=20
2025-09-04 20:53:14,910 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 20:53:26,120 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=15
2025-09-04 20:53:36,266 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:11:31,142 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:11:41,332 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:11:57,467 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:12:03,132 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:14:11,446 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:14:17,577 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:14:32,769 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:14:39,130 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:16:11,767 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:16:18,047 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:16:27,391 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:16:32,009 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:16:48,847 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:16:54,786 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:19:40,929 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:19:46,119 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:20:02,301 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:20:08,498 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:20:49,804 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:20:54,855 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:21:11,517 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:21:18,154 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:21:50,168 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:21:54,638 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:22:10,275 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:22:16,605 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:22:47,987 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:22:52,654 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:22:59,939 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:23:05,368 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:23:35,581 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:23:41,133 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:26:09,847 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:26:13,998 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:26:18,813 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:26:33,935 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=auto analyze=True
2025-09-04 21:26:39,694 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:26:57,389 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=5
2025-09-04 21:27:04,064 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-04 21:28:41,499 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-04 21:28:43,444 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:28:44,536 [INFO] dash.ai: news.summary: asset=BTC model_pref=gemini items=1
2025-09-04 21:28:49,886 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:28:51,672 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:28:57,223 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:29:56,934 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:29:58,801 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:30:04,206 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:30:32,044 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:30:33,631 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:30:37,427 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:31:35,613 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:31:37,410 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:31:41,430 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:31:51,313 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:31:53,084 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:31:57,049 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:34:27,106 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:34:28,794 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:34:32,972 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:36:15,357 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:36:16,952 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:36:20,936 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:36:46,835 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:36:48,748 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:36:52,729 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:39:47,957 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:39:49,834 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:39:53,586 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:43:08,339 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:43:10,210 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:43:14,162 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:50:37,942 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:50:40,579 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:50:44,657 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:53:48,187 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:53:50,148 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:53:54,395 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:54:48,023 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:54:51,366 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:54:55,525 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:54:55,564 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:54:59,431 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:55:00,924 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:55:02,697 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:55:09,280 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:55:12,377 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:58:47,989 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:58:50,031 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:58:54,492 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:58:58,151 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:59:00,034 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:59:04,081 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 21:59:18,383 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 21:59:20,278 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 21:59:24,735 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:01:54,574 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:01:56,366 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:02:00,444 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:02:08,472 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:02:11,753 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:02:16,208 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:02:47,972 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:02:50,256 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:02:54,371 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:06:21,459 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:06:25,154 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:06:29,307 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:06:46,808 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:06:48,741 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:06:52,942 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:07:11,398 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:07:13,223 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:07:17,485 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:11:48,000 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:11:51,143 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:11:55,430 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:13:48,007 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:13:50,337 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:13:54,463 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:14:45,663 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:14:47,515 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:14:51,905 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:16:47,356 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:16:49,099 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:16:55,007 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:16:57,757 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:17:01,596 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:17:07,772 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:17:09,639 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:17:15,485 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:17:34,194 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:17:37,293 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:17:41,515 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:18:50,885 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:18:54,308 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:18:59,832 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:19:39,280 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:19:41,633 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:19:46,991 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:23:47,976 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:23:51,364 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:23:57,143 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:30:46,962 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:30:49,433 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:30:53,367 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:42:59,690 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:43:02,228 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:43:06,704 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:45:47,966 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:45:49,754 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:45:54,689 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:47:06,217 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:47:09,548 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:47:13,950 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:49:12,150 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:49:13,954 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:49:18,790 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:51:34,216 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:51:36,070 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:51:40,627 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:52:18,347 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:52:20,351 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:52:25,529 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:53:11,909 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:53:17,512 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:53:21,081 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:53:21,886 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:53:21,947 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:53:22,108 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:53:22,803 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:53:23,560 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:53:23,767 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:53:33,091 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:53:36,154 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:53:39,372 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:55:23,417 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:55:25,088 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:55:28,680 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:56:47,853 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 22:56:56,597 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 22:57:02,979 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:57:08,866 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 22:57:12,682 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:57:14,099 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:57:14,651 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:57:20,874 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:57:24,083 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:57:25,828 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:57:29,083 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:57:48,013 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:57:50,192 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:57:53,991 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:57:57,974 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:57:59,943 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:58:03,679 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 22:58:12,041 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 22:58:14,000 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 22:58:14,580 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:01:47,994 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:01:52,055 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:01:56,832 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:02:49,218 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:02:52,825 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:02:56,793 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:03:38,703 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:03:42,559 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:03:46,998 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:03:52,481 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:04:01,327 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:04:18,364 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:04:33,828 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:04:42,075 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:04:58,174 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:05:08,087 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-09-04 23:05:15,716 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:05:48,089 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=10
2025-09-04 23:07:01,400 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-09-04 23:07:10,556 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:07:43,928 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-09-04 23:07:52,488 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:08:21,639 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=10
2025-09-04 23:08:22,099 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:08:23,844 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:08:26,160 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:08:26,315 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:08:27,734 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:08:30,219 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:08:38,878 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:08:40,395 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:08:43,132 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:08:46,755 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:08:53,895 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:09:09,328 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:09:36,129 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:09:42,504 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:09:57,694 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:10:32,397 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:10:39,533 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:10:55,483 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:11:03,163 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:11:13,796 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:11:29,468 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:13:02,324 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:13:07,697 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:13:11,844 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:13:14,094 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:13:26,980 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:13:29,118 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:13:55,039 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:13:58,049 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:14:00,437 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:14:05,385 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:14:07,362 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:14:09,917 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:18:21,828 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:18:29,111 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:18:44,250 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:18:47,615 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:18:53,943 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:18:54,453 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:18:55,258 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:18:56,563 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:18:56,568 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:18:59,059 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:18:59,074 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:19:04,559 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:19:06,653 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:19:09,545 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:19:13,133 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:19:13,581 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:19:15,365 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:19:15,894 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:19:17,805 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:19:19,365 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:29:36,896 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:29:39,168 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:29:41,639 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:29:52,057 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:30:00,587 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:30:15,781 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:30:31,904 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-04 23:30:41,067 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:30:57,632 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-04 23:32:55,870 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:32:58,409 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:33:00,495 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:33:01,065 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:33:13,500 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:33:15,546 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:33:23,478 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:33:26,611 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:33:29,052 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:34:35,990 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:34:38,143 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:34:40,530 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:34:48,611 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:34:50,771 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:34:53,255 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:35:55,493 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:35:58,803 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:36:01,231 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:36:05,608 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:36:26,236 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:36:28,446 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:36:30,899 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:36:41,739 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:36:43,859 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:36:46,267 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:38:22,623 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:38:26,571 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:38:29,009 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:38:47,937 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:38:50,081 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:38:52,558 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:40:14,828 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:40:17,829 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:40:20,291 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:40:27,520 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:40:29,573 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:40:32,181 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:40:34,507 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:40:35,044 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:40:37,370 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:40:39,797 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:40:40,322 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:40:42,733 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:40:47,227 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:40:49,485 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:40:51,884 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:41:57,379 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:41:59,763 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:42:02,194 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:42:35,808 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:42:38,952 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:42:39,277 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:42:41,443 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:42:41,844 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:42:43,869 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:42:47,508 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:42:52,878 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:42:55,317 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:43:19,581 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:43:21,709 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:43:24,132 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:43:48,485 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:43:54,508 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:43:57,095 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:44:09,648 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:44:09,772 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:44:12,375 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:44:12,789 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:44:14,822 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:44:15,160 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:44:23,729 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:44:26,592 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:44:29,020 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:45:12,295 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:45:14,739 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:45:17,138 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:46:03,111 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:46:05,484 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:46:05,956 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:46:07,798 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:46:08,501 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:46:10,221 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:46:17,427 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:46:20,596 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:46:23,267 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:46:34,236 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:46:36,587 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:46:39,024 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:46:46,040 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:46:48,353 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:46:50,970 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:47:28,786 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:47:31,161 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:47:33,590 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:47:48,851 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:47:51,567 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:47:54,127 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:47:58,073 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:48:01,148 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:48:03,668 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:51:16,088 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:51:18,758 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:51:21,153 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:51:21,328 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:51:23,294 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:51:25,930 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:52:26,097 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:52:28,327 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:52:30,798 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:52:55,606 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:53:01,464 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:53:03,939 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:53:51,690 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:53:55,885 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:53:58,481 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:54:14,094 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:54:20,057 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:54:22,487 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:54:47,366 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:54:49,829 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:54:52,315 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:54:59,005 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:55:02,175 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:55:04,606 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:55:11,004 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:55:13,520 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:55:16,004 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:55:31,970 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:55:34,587 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:55:37,166 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:56:03,384 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:56:06,034 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:56:08,902 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:56:16,237 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:56:19,569 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:56:22,075 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:56:26,901 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:56:29,222 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:56:31,646 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:57:58,456 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:58:00,946 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:58:03,436 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:58:07,733 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:58:11,696 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:58:14,188 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:58:46,606 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:58:49,001 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:58:51,613 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-04 23:59:22,943 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-04 23:59:25,177 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-04 23:59:27,604 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:00:11,777 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:00:14,048 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:00:16,511 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:00:19,533 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:00:21,814 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:00:24,260 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:00:41,939 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:00:44,382 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:00:45,700 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:00:46,848 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:00:48,780 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:00:51,299 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:00:56,871 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:00:59,378 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:01:06,924 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:01:08,970 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:01:11,481 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:01:59,953 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:02:02,278 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:02:04,724 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:02:09,939 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:02:12,118 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:02:16,244 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:02:18,492 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:02:20,950 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:02:23,926 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:02:26,500 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:02:28,905 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:02:46,047 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:02:48,337 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:02:50,751 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:03:13,703 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:03:16,999 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:03:19,619 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:03:26,733 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:03:29,199 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:03:31,634 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:03:41,282 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:03:43,523 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:03:45,939 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:05:47,323 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:05:49,786 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:05:52,235 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:05:56,695 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:06:02,267 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:06:04,796 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:06:47,958 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:06:51,035 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:06:53,510 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:07:48,054 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:07:53,474 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:07:55,902 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:07:56,531 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:07:59,100 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:01,522 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:05,828 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:08,761 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:09,909 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:11,270 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:14,163 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:15,073 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:16,990 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:17,840 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:20,442 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:27,024 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:29,567 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:31,979 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:47,725 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:50,147 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:52,518 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:52,612 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:54,642 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:08:57,262 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:58,424 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:58,461 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:08:59,482 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:08:59,773 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:01,802 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:01,818 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:02,223 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:02,699 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:09:03,114 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:09:03,296 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:09:04,367 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:04,371 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:05,381 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:05,992 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:06,856 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:07,936 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:08,447 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:09,333 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:13,569 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:09:15,916 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:18,312 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:24,377 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:09:26,406 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:28,834 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:09:51,448 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:09:53,648 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:09:56,070 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 00:10:00,119 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 00:10:02,228 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 00:10:04,776 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 09:06:55,711 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 09:06:59,736 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=20 model_pref=local analyze=True
2025-09-05 09:07:00,431 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:07:01,593 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=20 model_pref=auto analyze=True
2025-09-05 09:07:05,258 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 09:07:11,213 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:07:13,125 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:08:24,836 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=20
2025-09-05 09:08:25,041 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=20
2025-09-05 09:11:51,963 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=20 model_pref=auto analyze=True
2025-09-05 09:12:02,000 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:12:34,264 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:12:39,080 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:12:46,550 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:22:29,228 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:22:32,886 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:22:37,636 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:44:25,431 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:44:27,696 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:44:30,492 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:45:08,560 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:45:10,906 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:45:13,783 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:46:52,595 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:46:54,520 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:46:57,320 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:47:42,835 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:47:44,479 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:47:46,259 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:47:47,673 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:47:47,841 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:47:47,978 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:47:49,549 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:47:50,593 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:47:51,759 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:48:53,565 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:48:55,188 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:48:57,652 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:52:19,272 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:52:20,864 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:52:23,272 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:53:57,682 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:54:01,306 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:54:02,839 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:54:05,358 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:56:00,346 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:56:01,953 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:56:02,713 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:56:04,213 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:56:04,647 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:56:06,511 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:58:24,530 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:58:26,308 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:58:28,643 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:58:29,499 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:58:31,145 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:58:31,778 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 09:58:33,485 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 09:58:33,565 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 09:58:35,684 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:00:15,569 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:00:17,284 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:00:20,731 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:00:29,287 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:00:30,934 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:00:32,159 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:00:33,956 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:00:34,175 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:00:36,070 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:00:36,347 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:00:37,792 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:00:40,069 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:00:40,169 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:00:41,989 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:00:44,585 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:02:59,160 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:03:00,856 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:03:04,156 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:03:04,282 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:03:05,976 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:03:08,322 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:06:32,562 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:06:34,997 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:06:38,145 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:07:50,122 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:07:55,551 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:07:55,591 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:08:01,392 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:08:01,491 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:08:07,142 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:12:43,558 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:12:45,943 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:12:49,714 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:13:36,746 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:13:39,674 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:13:41,925 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:13:45,947 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:15:39,260 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:15:41,647 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:15:44,477 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:16:52,295 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:16:54,599 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:16:57,122 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:17:14,252 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:17:16,467 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:17:23,301 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:17:25,494 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:17:28,463 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:18:25,376 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:18:27,620 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:18:34,362 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:18:36,614 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:18:39,649 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:18:50,138 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:18:50,798 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:18:52,443 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:18:53,070 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:18:55,342 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:18:56,496 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:18:58,533 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:19:00,946 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:19:02,575 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:19:03,784 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:19:04,919 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:19:07,732 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:20:03,390 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:20:05,822 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:20:08,743 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:20:31,029 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:20:33,355 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:20:36,152 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:21:37,264 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:21:39,376 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:21:41,596 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 10:22:06,723 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 10:22:08,366 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 10:22:11,028 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:03:07,098 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:03:10,571 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:03:14,568 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:06:52,156 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 11:06:58,708 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:07:17,613 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 11:09:56,175 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:09:59,682 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:10:04,842 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:10:10,449 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:10:14,069 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:10:18,569 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:11:25,326 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:11:26,918 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:11:29,315 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:12:25,323 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:12:26,910 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:12:29,412 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:13:09,591 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:13:11,253 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:13:13,782 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:13:55,530 [INFO] dash.ai: news.fetch: asset=AMZN days=7 max=6 model_pref=auto analyze=True
2025-09-05 11:14:01,961 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:14:20,661 [INFO] dash.ai: news.summary: asset=AMZN model_pref=auto items=6
2025-09-05 11:15:18,883 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-05 11:15:20,489 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:15:22,913 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-05 11:19:47,250 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 11:19:53,000 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:20:15,397 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 11:28:43,307 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 11:28:48,947 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:29:03,706 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 11:35:11,052 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 11:35:15,711 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:35:31,070 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 11:58:48,605 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 11:58:54,450 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 11:59:15,816 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 12:18:05,145 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 12:18:29,087 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 12:18:59,803 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 13:33:11,258 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 13:33:16,842 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 13:33:32,708 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 13:34:52,767 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 13:34:59,167 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:40:42,655 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=auto analyze=True
2025-09-05 14:41:03,781 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:42:05,202 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=10
2025-09-05 14:42:09,739 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-05 14:43:14,880 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-05 14:43:34,187 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:44:12,561 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-05 14:45:26,517 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-05 14:45:39,715 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-09-05 14:45:46,038 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:45:58,881 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:46:27,161 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-05 14:46:42,178 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=5
2025-09-05 14:52:38,902 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 14:52:40,940 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:52:42,428 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 14:52:44,599 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 14:52:44,961 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 14:52:48,245 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 17:37:26,821 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 17:37:29,331 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 17:37:29,853 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 17:38:12,582 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 17:38:14,659 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 17:38:15,514 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 17:39:32,884 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 17:39:40,286 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 17:39:51,473 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 17:40:40,392 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-05 17:42:45,378 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 17:42:47,596 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 17:42:47,974 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 17:45:24,814 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 17:45:27,433 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 17:45:28,709 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 17:49:30,612 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 17:49:33,031 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 17:49:34,268 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:06:24,821 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 18:06:27,013 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:06:27,430 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:23:24,822 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 18:23:27,391 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:23:27,845 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:25:24,808 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 18:25:26,397 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:25:26,792 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:27:24,818 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 18:27:26,496 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:27:26,958 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:28:24,831 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 18:28:26,476 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:28:26,886 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:33:15,636 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-05 18:33:17,959 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:33:18,425 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-05 18:34:12,023 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 18:34:34,020 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 18:34:58,481 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-05 18:35:46,700 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-05 21:57:36,824 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-05 21:57:44,042 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-05 21:57:53,789 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 11:12:55,293 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:12:57,354 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:12:58,004 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:12:59,051 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:12:59,575 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:12:59,900 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:00,145 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:13:00,821 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:13:01,868 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:13:02,086 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:03,303 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:04,353 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:04,711 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:13:05,338 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:13:06,260 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:13:06,864 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:13:08,751 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:09,307 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:10,446 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:13:12,042 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:13:14,529 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:13:33,053 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:13:35,728 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:13:38,137 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:14:41,141 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:14:42,871 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:14:45,376 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:14:47,413 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:14:48,062 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:14:48,887 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:14:49,577 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:14:50,032 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:14:51,399 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:14:51,429 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:14:51,546 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:14:52,150 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:14:53,036 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:14:53,997 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:14:55,477 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:15:40,294 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:15:41,851 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:15:47,547 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:15:49,078 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:15:53,521 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:15:54,990 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:15:57,430 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:16:08,591 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:16:10,171 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:16:12,604 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:16:23,698 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:16:25,280 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:16:27,746 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:16:34,974 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:16:36,506 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:20:51,438 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:20:53,202 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:20:54,098 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:20:54,929 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:20:55,687 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:20:55,761 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:20:56,632 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:20:56,931 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:20:58,212 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:20:58,217 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:20:58,480 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:20:59,114 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:20:59,897 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:21:00,931 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:21:02,543 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:21:45,536 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:21:47,143 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:21:49,600 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:23:48,074 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:23:49,871 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:23:55,567 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:23:57,130 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:23:59,534 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:27:28,424 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:27:30,211 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:27:34,608 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:27:36,201 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:27:38,642 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:27:43,368 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:27:44,980 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:37:51,236 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:37:52,914 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:37:53,516 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:37:54,039 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:37:54,509 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:37:55,115 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:37:55,513 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:37:56,575 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:37:57,060 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:37:57,198 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:37:57,686 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:37:59,709 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:38:26,381 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:38:27,942 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:38:30,367 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:47:41,329 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:47:43,128 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:47:46,467 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:47:47,378 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:47:47,380 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:47:48,215 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:47:48,954 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:47:49,547 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:47:51,159 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:47:59,570 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:48:02,660 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:48:05,642 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:48:36,611 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:48:38,193 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:48:40,708 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:48:42,014 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:48:42,270 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:48:42,415 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:48:43,546 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:48:45,656 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:48:58,289 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:52:13,057 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:52:14,843 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:52:18,917 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:52:54,840 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:52:56,433 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:53:00,436 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:55:54,020 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:55:55,873 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:56:00,198 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 11:59:50,359 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 11:59:52,281 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 11:59:52,737 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:01:13,312 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:01:15,189 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:01:15,619 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:01:40,589 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:01:42,269 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:01:42,712 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:01:50,974 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:01:52,569 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:01:52,978 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:05:22,258 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:05:23,431 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:05:24,044 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:05:24,470 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:05:24,913 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:05:25,034 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:05:25,467 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:05:26,572 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:05:26,992 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:05:31,832 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:05:33,375 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:05:33,845 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:08:48,080 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:08:49,507 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:08:50,093 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:08:50,562 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:08:51,104 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:08:51,507 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:27:09,004 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:27:10,889 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:27:11,318 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:27:23,953 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:27:25,445 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:27:25,897 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:27:33,406 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:27:38,571 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:27:53,992 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 12:28:32,116 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:28:33,661 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:28:34,188 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:32:31,628 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:32:35,336 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:32:36,562 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:32:37,009 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:32:37,206 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:32:37,643 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:32:47,061 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:32:53,497 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:33:10,028 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 12:34:30,989 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:34:32,823 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:34:33,415 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:34:33,904 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:34:35,665 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:34:36,252 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:34:36,259 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:34:39,969 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:34:41,560 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:34:45,404 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:34:58,742 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 12:35:00,973 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 12:36:08,349 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:36:09,467 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:36:09,835 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:36:10,430 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:36:11,004 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:36:11,296 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:36:11,673 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:36:11,853 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:36:12,274 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:36:17,648 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:36:22,632 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:36:38,599 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 12:40:52,829 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:40:53,882 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:40:57,025 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:40:57,059 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:40:57,694 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:40:57,738 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:41:05,364 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:41:11,294 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:41:27,044 [INFO] dash.ai: news.summary: asset=AAPL model_pref=auto items=6
2025-09-06 12:43:39,997 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=6 model_pref=auto analyze=True
2025-09-06 12:43:44,698 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:43:53,811 [INFO] dash.ai: news.summary: asset=NVDA model_pref=auto items=4
2025-09-06 12:46:08,377 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:46:10,357 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:46:10,824 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:46:11,281 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:46:11,871 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:46:12,273 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:48:44,566 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:48:47,972 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:48:50,489 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:48:53,580 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:48:55,056 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:49:00,428 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:49:03,008 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:49:04,481 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:53:15,500 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:53:18,695 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:53:20,734 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:53:40,683 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:53:43,227 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:53:45,228 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:54:25,647 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:54:28,218 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:54:29,783 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:54:50,172 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:54:52,729 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:54:54,150 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:55:29,900 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:55:32,588 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:55:34,535 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:55:47,822 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:55:53,213 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:55:56,352 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:55:57,828 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:56:29,200 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:56:32,302 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:56:33,818 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:57:45,430 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:57:48,156 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:57:50,224 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:58:20,187 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:58:22,860 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:58:24,926 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 12:58:39,359 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 12:58:42,019 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 12:58:43,531 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:00:32,339 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-06 13:00:35,574 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:00:40,201 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-06 13:01:47,413 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-06 13:01:51,305 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-06 13:01:54,570 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:01:57,519 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 13:01:58,887 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 13:01:59,229 [INFO] dash.ai: news.summary: asset=BTC model_pref=auto items=1
2025-09-06 13:02:00,575 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:02:01,476 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:02:02,542 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:02:03,003 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:03:01,205 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 13:03:03,925 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:03:05,419 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:03:35,689 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 13:03:38,259 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:03:39,446 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:03:56,719 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 13:03:59,809 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:04:01,369 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:09:18,026 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-06 13:09:21,255 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:09:33,269 [INFO] dash.ai: news.summary: asset=BTC model_pref=local items=1
2025-09-06 13:10:13,579 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 13:10:16,715 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:10:23,285 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 13:10:52,684 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:10:59,887 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:11:13,375 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:14:07,746 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:14:12,946 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:14:17,914 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:14:20,864 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:14:30,056 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 13:14:34,146 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:14:35,094 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:14:45,324 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:15:14,412 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 13:18:31,250 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:18:39,562 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:18:54,897 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:21:30,392 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:21:39,214 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:21:48,002 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:21:54,194 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:22:02,745 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:22:17,992 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:23:34,224 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:23:41,840 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:23:57,798 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:32:34,204 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:32:43,468 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:32:59,664 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:48:34,224 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:48:42,644 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:48:58,944 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:50:34,193 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:50:43,304 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:50:58,890 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 13:56:20,651 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 13:56:29,441 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 13:56:44,417 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 14:00:51,491 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 14:01:05,904 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:01:32,222 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 14:09:57,918 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 14:09:59,188 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 14:10:08,385 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:10:08,802 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:10:12,244 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 14:10:23,347 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 14:10:24,320 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 14:10:26,958 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:10:54,596 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 14:23:13,001 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=gemini analyze=True
2025-09-06 14:23:21,534 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:23:23,631 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=auto analyze=True
2025-09-06 14:23:31,249 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:23:37,745 [INFO] dash.ai: news.summary: asset=ETH model_pref=gemini items=5
2025-09-06 14:23:46,032 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-06 14:37:35,985 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 14:37:48,740 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 14:38:11,387 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-06 15:41:43,287 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 15:41:55,068 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 15:42:17,394 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-06 16:28:01,811 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:28:04,191 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:28:05,221 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:28:06,680 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:28:07,431 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:28:09,390 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:28:11,576 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:28:13,941 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:28:14,884 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:28:46,280 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:28:50,054 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:28:51,032 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:29:42,519 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:29:45,023 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:29:55,519 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:31:50,924 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:31:54,804 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:31:57,427 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:32:03,817 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:32:06,900 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:32:11,185 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:32:18,791 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:32:21,366 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:32:25,887 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:34:04,888 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:34:08,363 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:34:12,774 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:34:43,008 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:34:45,630 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:34:46,324 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:35:29,482 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:35:32,178 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:35:33,155 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:36:11,690 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:36:14,345 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:36:15,075 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:36:50,620 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:36:53,195 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:36:54,144 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:37:52,738 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-09-06 16:37:55,948 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:37:56,886 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-06 16:38:41,608 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:38:44,981 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:38:48,393 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:42:03,465 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:42:04,512 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:42:05,940 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:42:07,654 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:42:09,386 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:42:10,125 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:42:25,425 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 16:42:37,438 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:42:55,142 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-06 16:55:05,365 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:55:06,493 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:55:08,111 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:55:08,925 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:55:10,475 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:55:10,518 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:55:12,595 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 16:55:13,979 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-06 16:55:14,955 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-06 16:55:26,312 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:55:36,983 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:55:37,760 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:55:39,971 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:55:40,409 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:55:40,968 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:55:41,205 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=auto analyze=True
2025-09-06 16:55:42,538 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:55:42,953 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 16:55:43,891 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:55:45,056 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-06 16:55:55,053 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 16:55:57,712 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 16:56:08,286 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:56:11,103 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 16:56:20,754 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-06 16:56:22,256 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 16:56:29,190 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-06 16:56:30,736 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-06 16:56:31,511 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-06 17:58:22,781 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 17:58:37,638 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 17:58:48,367 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 18:07:28,852 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 18:07:43,525 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 18:07:59,875 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 18:14:48,163 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=auto analyze=True
2025-09-06 18:14:58,556 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 18:15:13,859 [INFO] dash.ai: news.summary: asset=GOOGL model_pref=local items=6
2025-09-06 18:25:55,971 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-06 18:26:08,268 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 18:26:22,623 [INFO] dash.ai: news.summary: asset=CRCL model_pref=local items=6
2025-09-06 21:09:52,722 [INFO] dash.ai: news.fetch: asset=META days=7 max=6 model_pref=auto analyze=True
2025-09-06 21:09:59,730 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 21:12:28,777 [INFO] dash.ai: news.summary: asset=META model_pref=local items=6
2025-09-06 21:19:44,368 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 21:19:57,168 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 21:20:35,941 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 21:21:18,191 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 21:22:02,463 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 21:23:56,625 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 21:24:24,440 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-06 23:56:14,153 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=10 model_pref=auto analyze=True
2025-09-06 23:56:24,923 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-06 23:57:18,674 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=10
2025-09-06 23:59:19,069 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=10 model_pref=auto analyze=True
2025-09-06 23:59:28,188 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 00:00:30,110 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=10
2025-09-07 13:02:59,510 [INFO] dash.ai: news.fetch: asset=None days=1 max=10 model_pref=auto analyze=True
2025-09-07 13:03:06,766 [INFO] dash.ai: news.fetch: asset=None days=1 max=10 model_pref=auto analyze=True
2025-09-07 13:04:09,805 [INFO] dash.ai: news.fetch: asset=None days=1 max=10 model_pref=auto analyze=True
2025-09-07 13:04:11,348 [INFO] dash.ai: news.fetch: asset=None days=1 max=10 model_pref=auto analyze=True
2025-09-07 13:04:12,788 [INFO] dash.ai: news.fetch: asset=None days=1 max=10 model_pref=auto analyze=True
2025-09-07 13:04:19,495 [INFO] dash.ai: news.fetch: asset=None days=1 max=1 model_pref=auto analyze=True
2025-09-07 13:05:13,000 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-07 13:05:15,561 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:05:18,674 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-07 13:10:24,542 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-07 13:10:26,103 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:10:29,036 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=1
2025-09-07 13:13:19,409 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 13:13:26,365 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:13:52,769 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 13:15:53,816 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 13:15:58,415 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 13:16:05,048 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 13:16:10,828 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:16:37,347 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 13:18:55,574 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 13:18:57,320 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-07 13:18:58,302 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-07 13:18:58,881 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:18:59,781 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:19:01,541 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 13:19:03,693 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-07 13:19:07,180 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=1
2025-09-07 13:19:47,190 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 15:07:53,633 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 15:08:00,134 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 15:08:28,852 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 15:09:17,753 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 15:09:24,408 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 15:09:50,274 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 15:48:28,274 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 15:48:29,126 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 15:48:36,864 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 15:48:36,941 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 15:49:23,578 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 15:49:26,371 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-07 15:49:33,744 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-07 15:49:38,446 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-07 15:50:22,004 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-08 15:59:26,324 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-09-08 15:59:32,612 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-08 15:59:33,118 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-08 15:59:38,051 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-08 15:59:38,695 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-08 15:59:44,251 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-08 15:59:47,084 [INFO] dash.ai: news.summary: asset=ETH model_pref=local items=5
2025-09-08 15:59:51,126 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-08 15:59:57,605 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-09 19:33:16,077 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-09 19:33:27,207 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-09 19:33:27,839 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-09 19:33:33,897 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-09 19:33:34,953 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-09 19:33:42,917 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-09 19:33:45,239 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-09 19:33:52,827 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-09 19:33:59,034 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-09 19:34:00,892 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-09 19:34:06,629 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-10 14:56:49,375 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-10 14:56:55,375 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-10 14:57:08,780 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 10:54:10,162 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 10:54:11,469 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 10:54:19,488 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 10:54:19,538 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 10:54:31,580 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 10:54:32,604 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 10:54:46,383 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=auto analyze=True
2025-09-11 10:54:51,052 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 10:55:11,851 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 11:00:40,943 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=auto analyze=True
2025-09-11 11:00:46,639 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:01:03,368 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 11:04:57,634 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:05:02,041 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:05:08,829 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:05:18,328 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:05:22,582 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:05:27,075 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:05:30,283 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:05:34,616 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:05:48,326 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:14:52,917 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:14:54,890 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:14:57,554 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-11 11:14:59,743 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:14:59,778 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:15:07,677 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:15:12,087 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:15:13,777 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:15:33,663 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-11 11:19:07,322 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:19:14,035 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:19:27,307 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:19:32,218 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:19:32,799 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:19:37,597 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:19:39,138 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:19:44,951 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-11 11:19:52,270 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:19:52,987 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:20:07,130 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:20:38,688 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-11 11:32:02,767 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:32:03,809 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:32:05,728 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=auto analyze=True
2025-09-11 11:32:11,231 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:32:11,277 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:32:12,151 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:32:26,575 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:32:27,670 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:32:30,989 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-11 11:40:04,475 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:40:05,853 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:40:11,294 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:40:11,336 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:40:19,645 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=local analyze=True
2025-09-11 11:40:24,967 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:40:25,200 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:40:26,615 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:40:29,598 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 11:50:02,249 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:50:04,220 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:50:07,934 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=local analyze=True
2025-09-11 11:50:09,998 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:50:10,010 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:50:12,620 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:50:25,288 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:50:25,934 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:50:44,189 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 11:52:23,148 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=local analyze=True
2025-09-11 11:52:27,632 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:52:31,478 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 11:55:01,043 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:55:06,717 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:55:16,809 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 11:55:20,278 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 11:55:23,783 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 11:55:38,878 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:09:28,784 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:09:30,028 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:09:38,068 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:09:38,133 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:09:55,365 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:09:55,542 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:38:22,387 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:38:30,094 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:38:45,795 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:42:54,947 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:42:56,004 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:43:02,403 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:43:02,452 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:43:08,199 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 12:43:15,635 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:43:19,631 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:43:19,985 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:43:57,207 [INFO] dash.ai: news.summary: asset=AAPL model_pref=local items=6
2025-09-11 12:48:45,966 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:48:52,667 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:48:59,784 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:49:07,896 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:49:08,738 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:49:13,910 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:49:15,045 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:49:29,635 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:49:29,866 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:49:42,330 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=local analyze=True
2025-09-11 12:49:47,182 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:50:19,480 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 12:54:07,210 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:54:14,608 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:54:30,935 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:57:11,804 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:57:12,510 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 12:57:19,803 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:57:19,870 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:57:21,144 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=local analyze=True
2025-09-11 12:57:27,097 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 12:57:46,445 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:57:50,649 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 12:58:02,025 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-11 12:58:06,321 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-11 12:58:09,760 [INFO] dash.ai: news.summary: asset=AVGO model_pref=local items=6
2025-09-11 13:02:49,333 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 13:02:57,166 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 13:03:07,918 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 13:03:08,961 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 13:03:15,176 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:03:15,778 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:03:24,383 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-11 13:03:32,735 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:04:10,239 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 13:04:19,030 [INFO] dash.ai: news.summary: asset=ETH model_pref=auto items=5
2025-09-11 13:04:21,293 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-11 13:04:25,129 [INFO] dash.ai: news.summary.DO: POST /chat/completions model=llama3-8b-instruct status=200
2025-09-11 13:04:33,707 [INFO] dash.ai: news.summary: asset=CRCL model_pref=auto items=6
2025-09-11 13:08:50,585 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-11 13:09:00,448 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:15:16,313 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=auto analyze=True
2025-09-11 13:15:21,083 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:15:55,056 [INFO] dash.ai: news.summary: asset=AVGO model_pref=auto items=6
2025-09-11 13:26:20,870 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-11 13:26:28,275 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:27:03,787 [INFO] dash.ai: news.summary: asset=CRCL model_pref=auto items=6
2025-09-11 13:38:10,432 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=auto analyze=True
2025-09-11 13:38:15,200 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 13:38:46,523 [INFO] dash.ai: news.summary: asset=AVGO model_pref=auto items=6
2025-09-11 14:51:01,159 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=6 model_pref=auto analyze=True
2025-09-11 14:51:06,944 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 14:51:42,021 [INFO] dash.ai: news.summary: asset=NVDA model_pref=auto items=6
2025-09-11 15:01:39,626 [INFO] dash.ai: news.fetch: asset=ETH-USD days=7 max=6 model_pref=auto analyze=True
2025-09-11 15:01:46,588 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 15:02:18,298 [INFO] dash.ai: news.summary: asset=ETH-USD model_pref=auto items=6
2025-09-11 15:06:49,379 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=auto analyze=True
2025-09-11 15:06:57,361 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 15:07:31,702 [INFO] dash.ai: news.summary: asset=CRCL model_pref=auto items=6
2025-09-11 15:27:46,781 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=auto analyze=True
2025-09-11 15:28:00,606 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 15:28:36,843 [INFO] dash.ai: news.summary: asset=GOOGL model_pref=auto items=6
2025-09-11 15:29:58,420 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=auto analyze=True
2025-09-11 15:30:06,433 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 15:30:42,851 [INFO] dash.ai: news.summary: asset=GOOGL model_pref=auto items=6
2025-09-11 15:51:40,412 [INFO] dash.ai: news.fetch: asset=AMZN days=7 max=6 model_pref=auto analyze=True
2025-09-11 15:51:46,856 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 15:59:47,757 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=local analyze=True
2025-09-11 15:59:54,167 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:03:22,730 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=local analyze=True
2025-09-11 16:03:30,641 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:08:41,317 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 16:08:49,121 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:11:38,293 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 16:11:43,225 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:22:46,653 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=local analyze=True
2025-09-11 16:22:54,133 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:31:35,794 [INFO] dash.ai: news.fetch: asset=AMZN days=7 max=6 model_pref=local analyze=True
2025-09-11 16:31:40,965 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:36:21,097 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 16:36:29,890 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:44:50,468 [INFO] dash.ai: news.fetch: asset=AMD days=7 max=6 model_pref=local analyze=True
2025-09-11 16:45:02,066 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:50:15,501 [INFO] dash.ai: news.fetch: asset=TSM days=7 max=6 model_pref=local analyze=True
2025-09-11 16:50:27,698 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 16:53:44,976 [INFO] dash.ai: news.fetch: asset=SMCI days=7 max=6 model_pref=local analyze=True
2025-09-11 16:53:54,142 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:17:00,333 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=local analyze=True
2025-09-11 18:17:08,403 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:20:45,467 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 18:20:51,867 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:26:49,411 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=local analyze=True
2025-09-11 18:26:57,090 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:31:36,117 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 18:31:42,351 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:34:38,413 [INFO] dash.ai: news.fetch: asset=AVGO days=7 max=6 model_pref=local analyze=True
2025-09-11 18:34:43,464 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:41:41,672 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-11 18:41:48,693 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:48:29,644 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=6 model_pref=local analyze=True
2025-09-11 18:48:37,107 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 18:57:38,602 [INFO] dash.ai: news.fetch: asset=AMD days=7 max=6 model_pref=local analyze=True
2025-09-11 18:57:49,214 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 19:12:49,967 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-11 19:12:53,872 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 19:13:29,671 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=6 model_pref=local analyze=True
2025-09-11 19:13:36,649 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 19:16:02,117 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-11 19:16:05,452 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 19:23:58,227 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-11 19:24:01,199 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-11 19:28:46,958 [INFO] dash.ai: news.fetch: asset=MSFT days=7 max=6 model_pref=local analyze=True
2025-09-11 19:28:52,709 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:02:05,434 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-12 15:02:11,266 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:04:38,954 [INFO] dash.ai: news.fetch: asset=TSLA days=7 max=6 model_pref=local analyze=True
2025-09-12 15:04:46,595 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:15:22,372 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-12 15:15:24,732 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:20:25,254 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-12 15:20:27,768 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:21:28,314 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-12 15:21:29,914 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:36:44,458 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-12 15:36:47,417 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:39:17,911 [INFO] dash.ai: news.fetch: asset=TSLA days=1 max=1 model_pref=local analyze=True
2025-09-12 15:39:19,895 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-12 15:40:05,047 [INFO] dash.ai: news.fetch: asset=TSLA days=1 max=5 model_pref=auto analyze=True
2025-09-12 15:40:11,847 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 10:12:24,825 [INFO] dash.ai: news.fetch: asset=TSLA days=1 max=1 model_pref=auto analyze=True
2025-09-15 10:12:27,403 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 10:12:28,897 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 10:12:30,558 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-15 10:12:32,743 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-15 10:12:32,744 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 10:12:39,230 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 10:12:40,690 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 10:19:12,380 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=10 model_pref=auto analyze=True
2025-09-15 10:19:20,792 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 19:40:07,918 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=10 model_pref=auto analyze=True
2025-09-15 19:40:10,435 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-15 19:40:18,239 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 19:40:18,270 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 19:42:15,653 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=local analyze=True
2025-09-15 19:42:21,752 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:06:25,395 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=auto analyze=True
2025-09-15 23:06:32,823 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:06:33,967 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:06:35,597 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:07:19,743 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:07:21,466 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:08:07,873 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:08:09,545 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:08:57,876 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:08:59,501 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:09:41,928 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:09:43,541 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:10:49,286 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:10:50,731 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:11:29,082 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:11:30,592 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:11:58,622 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:12:00,170 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:12:05,276 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:12:06,827 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:12:37,578 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:12:38,046 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:12:39,097 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:12:39,599 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:15:24,823 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:15:26,398 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:15:55,942 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:16:17,703 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:16:19,171 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:16:54,367 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:16:55,977 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:18:19,833 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:18:21,409 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:20:33,608 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:20:35,295 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:21:20,675 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:24:33,580 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:24:35,153 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:25:15,717 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:25:17,383 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:25:49,958 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:25:51,508 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:27:03,791 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:27:05,452 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:27:19,739 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:27:21,256 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:27:37,682 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-15 23:27:39,268 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:30:23,917 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=10 model_pref=local analyze=True
2025-09-15 23:30:29,026 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:41:13,034 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=10 model_pref=local analyze=True
2025-09-15 23:41:16,246 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=10 model_pref=local analyze=True
2025-09-15 23:41:20,338 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:46:36,278 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-15 23:46:37,874 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:47:24,513 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-15 23:47:29,435 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-15 23:51:00,063 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-15 23:51:01,812 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 00:04:43,944 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 00:04:45,858 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 00:05:30,653 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 00:05:32,939 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:01:05,337 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:01:07,405 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:01:08,350 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:01:08,583 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:01:09,137 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:01:09,255 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:01:10,031 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:01:10,136 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:01:11,058 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:01:11,791 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:08:18,835 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:08:20,883 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 10:08:23,097 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:08:23,190 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 10:08:23,948 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 10:08:25,573 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 14:29:50,932 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 14:29:55,572 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 14:30:50,907 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 14:30:52,457 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 14:35:50,933 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 14:35:52,368 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 14:38:50,914 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 14:38:52,368 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:34:40,572 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:34:43,928 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:34:49,144 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:34:51,774 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:36:22,794 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:36:27,390 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:36:37,070 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:36:39,185 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:43:32,585 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=local analyze=True
2025-09-16 15:43:41,557 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:52:58,223 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:53:02,932 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:53:46,214 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:53:47,865 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 15:53:54,101 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 15:53:55,664 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 16:53:51,166 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 16:53:54,355 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 16:57:17,599 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=local analyze=True
2025-09-16 16:57:29,748 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 17:04:27,527 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=auto analyze=True
2025-09-16 17:04:38,639 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 19:43:47,150 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=auto analyze=True
2025-09-16 19:43:49,147 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=auto analyze=True
2025-09-16 19:43:57,962 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 19:43:58,233 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 19:44:17,630 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=auto analyze=True
2025-09-16 19:44:22,399 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 19:51:42,834 [INFO] dash.ai: news.fetch: asset=MSFT days=7 max=6 model_pref=local analyze=True
2025-09-16 19:51:48,120 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 20:09:27,501 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:09:29,923 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 20:19:15,757 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:19:18,027 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 20:19:33,992 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:19:35,902 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 20:28:18,166 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:28:22,034 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 20:28:33,545 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:28:37,422 [INFO] dash.ai: news.fetch: providers use_do=False use_hf=False have_keys do=True hf=True
2025-09-16 20:35:20,029 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:38:44,203 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:42:17,106 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:42:47,218 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:48:48,314 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:52:50,658 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 20:55:12,323 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 21:06:48,307 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 21:07:48,361 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 21:09:39,612 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=auto analyze=True
2025-09-16 21:11:38,417 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:14:48,744 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:15:48,032 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:17:48,425 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:17:57,058 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:19:48,307 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:20:30,053 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:23:18,263 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:23:28,068 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:26:33,752 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:26:45,270 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:27:12,773 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:27:18,668 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-16 21:27:53,640 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-16 21:30:30,436 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:30:40,767 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:31:58,215 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 21:32:10,956 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:36:59,070 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-09-16 21:37:00,248 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:37:27,996 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:37:29,177 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:38:16,022 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:38:25,888 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:40:48,449 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:40:57,690 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:44:38,165 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:44:46,435 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:45:09,604 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:45:18,095 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:50:16,814 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:50:27,319 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:50:35,220 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:50:45,998 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:58:01,817 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 21:58:15,358 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:58:39,710 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-09-16 21:58:46,179 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-16 22:00:04,405 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 298, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-09-16 22:00:08,927 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 22:00:10,360 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 22:00:12,830 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-09-16 22:00:12,830 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-09-16 22:00:13,394 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-09-16 22:00:13,394 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-09-16 22:00:15,139 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-16 22:00:15,158 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-16 22:00:24,958 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-16 22:00:57,723 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-16 22:09:03,856 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-16 22:10:16,619 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 22:10:16,627 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-09-16 22:10:16,628 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-09-16 22:10:18,701 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-16 22:16:26,802 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-09-16 22:16:26,808 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-09-16 22:16:26,808 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-09-16 22:16:28,669 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:29:42,890 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-18 23:29:52,657 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EEF93EF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
    ~~~~~~~~~~~~^^^^
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
    ~~~~~~~~~~~~^
        method,
        ^^^^^^^
    ...<6 lines>...
        enforce_content_length=enforce_content_length,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 494, in request
    self.endheaders()
    ~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1093, in _send_output
    self.send(msg)
    ~~~~~~~~~^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1037, in send
    self.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 325, in connect
    self.sock = self._new_conn()
                ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
        self, f"Failed to establish a new connection: {e}"
    ) from e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001EEF93EF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EEF93EF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 298, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 677, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EEF93EF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2025-09-18 23:29:54,635 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:30:37,115 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-18 23:30:43,646 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246F04FF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
    ~~~~~~~~~~~~^^^^
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
    ~~~~~~~~~~~~^
        method,
        ^^^^^^^
    ...<6 lines>...
        enforce_content_length=enforce_content_length,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 494, in request
    self.endheaders()
    ~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1093, in _send_output
    self.send(msg)
    ~~~~~~~~~^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1037, in send
    self.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 325, in connect
    self.sock = self._new_conn()
                ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
        self, f"Failed to establish a new connection: {e}"
    ) from e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000246F04FF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246F04FF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 298, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 677, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246F04FF620>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2025-09-18 23:30:44,738 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:41:53,682 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:42:01,508 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B39FFCBED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
    ~~~~~~~~~~~~^^^^
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
    ~~~~~~~~~~~~^
        method,
        ^^^^^^^
    ...<6 lines>...
        enforce_content_length=enforce_content_length,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 494, in request
    self.endheaders()
    ~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1093, in _send_output
    self.send(msg)
    ~~~~~~~~~^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1037, in send
    self.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 325, in connect
    self.sock = self._new_conn()
                ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
        self, f"Failed to establish a new connection: {e}"
    ) from e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002B39FFCBED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B39FFCBED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1085, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 677, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002B39FFCBED0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2025-09-18 23:42:04,728 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:42:11,049 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024C0186CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
    ~~~~~~~~~~~~^^^^
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
    ~~~~~~~~~~~~^
        method,
        ^^^^^^^
    ...<6 lines>...
        enforce_content_length=enforce_content_length,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 494, in request
    self.endheaders()
    ~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1093, in _send_output
    self.send(msg)
    ~~~~~~~~~^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1037, in send
    self.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 325, in connect
    self.sock = self._new_conn()
                ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
        self, f"Failed to establish a new connection: {e}"
    ) from e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000024C0186CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024C0186CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1085, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 677, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024C0186CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2025-09-18 23:42:12,938 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:42:33,707 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:42:39,515 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C2EBB5CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
    ~~~~~~~~~~~~^^^^
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
    ~~~~~~~~~~~~^
        method,
        ^^^^^^^
    ...<6 lines>...
        enforce_content_length=enforce_content_length,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 494, in request
    self.endheaders()
    ~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1333, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1093, in _send_output
    self.send(msg)
    ~~~~~~~~~^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1037, in send
    self.connect()
    ~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 325, in connect
    self.sock = self._new_conn()
                ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 213, in _new_conn
    raise NewConnectionError(
        self, f"Failed to establish a new connection: {e}"
    ) from e
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002C2EBB5CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C2EBB5CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1085, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 677, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002C2EBB5CB90>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))
2025-09-18 23:42:40,935 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:44:54,409 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:46:26,049 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1085, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-09-18 23:46:30,590 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:48:03,570 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1085, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-09-18 23:48:05,477 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:52:20,818 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:53:27,451 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:55:27,594 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1111, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-09-18 23:55:29,704 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-18 23:56:04,534 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-09-18 23:57:38,243 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 1111, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-09-18 23:57:40,563 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-09-19 00:01:03,037 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-19 00:02:54,145 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-19 00:06:03,678 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-19 09:22:07,568 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-19 09:24:03,445 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=auto analyze=True
2025-09-19 09:24:06,262 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-19 09:25:11,032 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-19 09:25:12,046 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-19 09:25:13,351 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=auto analyze=True
2025-09-19 09:25:21,908 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-19 09:25:29,213 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:36,945 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:40,801 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:45,427 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:48,467 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:52,047 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:53,767 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-19 09:25:59,247 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-21 20:43:18,644 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 20:43:50,523 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 21:01:37,880 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 21:35:59,808 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 21:37:16,558 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-21 21:37:46,548 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-21 21:38:21,979 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-21 21:39:06,998 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 318, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-09-21 21:39:13,092 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 21:42:03,921 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 21:45:58,813 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-21 22:42:58,591 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-23 19:51:22,609 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=gemini analyze=True
2025-09-23 19:52:51,269 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=gemini analyze=True
2025-09-23 19:52:56,526 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=gemini analyze=True
2025-09-23 19:53:05,806 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=gemini analyze=True
2025-09-24 12:49:20,158 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=6 model_pref=local analyze=True
2025-09-24 12:49:30,039 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 12:49:31,603 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 12:49:33,180 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 12:49:35,125 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 12:49:43,531 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 12:49:45,578 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 12:49:55,410 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:15:47,758 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-09-24 13:16:33,526 [INFO] dash.ai: news.fetch: asset=TSMC days=7 max=1 model_pref=gemini analyze=True
2025-09-24 13:17:08,461 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=1 model_pref=gemini analyze=True
2025-09-24 13:25:04,485 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=1 model_pref=gemini analyze=True
2025-09-24 13:35:53,610 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:37:48,890 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:37:54,884 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:37:55,013 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:37:57,241 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:37:58,441 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:37:58,559 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:38:01,537 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:38:03,634 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:38:05,459 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:38:18,148 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:38:25,625 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:38:27,962 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:38:31,822 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:38:35,607 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:38:39,038 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:44:40,320 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:44:41,993 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:44:49,224 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:44:55,875 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:00,900 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:05,369 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:11,122 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:16,211 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:23,841 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:25,462 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:45:30,694 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:47:04,625 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:47:07,863 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=local-model status=200
2025-09-24 13:54:37,407 [INFO] dash.ai: news.fetch: asset=NVDA days=1 max=1 model_pref=gemini analyze=True
2025-09-24 13:55:29,021 [INFO] dash.ai: news.fetch: asset=GOOGL days=7 max=6 model_pref=local analyze=True
2025-09-24 13:55:44,072 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:55:46,788 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:55:52,297 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:55:58,458 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:56:06,810 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:56:08,630 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 13:56:14,414 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:06,178 [INFO] dash.ai: news.fetch: asset=NVDA days=7 max=6 model_pref=local analyze=True
2025-09-24 14:04:23,773 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:30,872 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:34,527 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:40,198 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:46,002 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:47,819 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 14:04:55,754 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:06,855 [INFO] dash.ai: news.fetch: asset=AAPL days=7 max=6 model_pref=local analyze=True
2025-09-24 15:03:22,528 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:28,374 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:33,309 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:39,797 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:44,178 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:45,871 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:03:51,553 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:29:29,882 [INFO] dash.ai: news.fetch: asset=TSLA days=7 max=6 model_pref=local analyze=True
2025-09-24 15:29:46,675 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:29:52,454 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:29:59,779 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:30:06,588 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:30:08,331 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:30:09,942 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:30:17,226 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:25,545 [INFO] dash.ai: news.fetch: asset=NFLX days=7 max=10 model_pref=local analyze=True
2025-09-24 15:54:37,603 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:44,290 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:45,756 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:50,318 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:52,379 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:53,931 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:55,647 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:57,001 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:54:58,993 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:55:00,943 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 15:55:15,444 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:07:32,691 [INFO] dash.ai: news.fetch: asset=MSTR days=14 max=10 model_pref=local analyze=True
2025-09-24 16:07:43,996 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:07:48,511 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:07:50,544 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:07:55,204 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:07:59,447 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:08:01,278 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:08:03,046 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:08:04,906 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:08:06,503 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 16:08:15,952 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-09-24 20:04:18,990 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=gemini analyze=True
2025-09-24 21:19:16,668 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=gemini analyze=True
2025-09-24 21:19:16,909 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=gemini analyze=True
2025-09-24 21:19:19,537 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=gemini analyze=True
2025-09-24 21:20:11,177 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=gemini analyze=True
2025-09-24 21:38:37,803 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=gemini analyze=True
2025-10-02 10:12:09,544 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=local analyze=True
2025-10-02 10:12:18,769 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-02 10:12:18,769 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4118 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-02 10:12:23,233 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:27,725 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:30,813 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:36,117 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:38,300 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:40,187 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:41,915 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:43,751 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:45,414 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:47,060 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:48,888 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:50,603 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:52,415 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:54,907 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:56,772 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:12:58,636 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:00,710 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:02,661 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:04,655 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:06,685 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:08,945 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:10,824 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:13,161 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:15,183 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:17,336 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:19,515 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:21,618 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:23,616 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:13:25,105 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:14:20,486 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-02 10:14:20,487 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4308 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-02 10:43:11,990 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=local analyze=True
2025-10-02 10:43:17,533 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-02 10:43:17,533 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4128 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-02 10:43:22,410 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:22,445 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-02 10:43:22,445 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4119 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-02 10:43:25,726 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:29,901 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:31,715 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:33,523 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:35,652 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:37,581 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:39,337 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:41,512 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:43,381 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:45,007 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:46,794 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:49,340 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:51,141 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:53,058 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:55,111 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:56,990 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:58,934 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:43:58,964 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-02 10:43:58,964 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4308 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-02 10:44:00,943 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:03,203 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:05,072 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:07,402 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:09,562 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:11,397 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:13,528 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:15,619 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:17,560 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:19,095 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-02 10:44:56,968 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-02 10:44:56,968 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5694 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 09:45:09,327 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=30 model_pref=local analyze=True
2025-10-03 09:45:11,669 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:45:23,966 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:45:36,445 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:45:40,895 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:45:47,909 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:45:49,678 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:45:51,532 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:46:04,619 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:54:05,676 [INFO] dash.ai: news.fetch: asset=AAPL days=14 max=5 model_pref=local analyze=True
2025-10-03 09:54:18,771 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:54:24,373 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:54:27,546 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:54:29,335 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:54:34,420 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:54:41,638 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:55:27,638 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:55:39,783 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:55:44,483 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:55:51,902 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:55:53,702 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:55:55,507 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:56:08,971 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:56:20,779 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:56:26,793 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:56:32,279 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:56:36,068 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:56:36,135 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 09:56:36,771 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:56:41,110 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:56:48,488 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 09:57:03,319 [INFO] dash.ai: news.fetch: asset=AAPL days=14 max=5 model_pref=local analyze=True
2025-10-03 09:57:15,099 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:57:19,770 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:57:25,388 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:57:28,625 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:57:36,319 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 09:57:40,516 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:06,415 [INFO] dash.ai: news.fetch: asset=TSLA days=14 max=10 model_pref=local analyze=True
2025-10-03 10:33:33,584 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:35,134 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:36,464 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:40,016 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:41,648 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:43,396 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:44,928 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:46,570 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:48,091 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:33:49,901 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:34:17,894 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:26,767 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-03 10:41:28,401 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 10:41:35,392 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:36,765 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:36,814 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=400
2025-10-03 10:41:36,814 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4114 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 10:41:36,841 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=400
2025-10-03 10:41:36,841 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4114 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 10:41:42,558 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:44,032 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:45,615 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:46,921 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:53,109 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:55,365 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:41:57,269 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:42:13,388 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:42:15,340 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:42:17,112 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:42:18,604 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:42:20,634 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:42:45,178 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 10:57:07,102 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 10:57:17,158 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:18,835 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:18,872 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 10:57:18,872 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4106 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 10:57:24,899 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:26,786 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:28,517 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:30,492 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:32,254 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:34,220 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:35,712 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 10:57:43,288 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 10:57:43,288 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4478 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 11:08:07,096 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 11:08:17,033 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:08:22,604 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:08:22,639 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 11:08:22,639 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4109 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 11:08:36,996 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 11:08:45,423 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:08:50,913 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:08:50,948 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 11:08:50,948 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4109 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 11:08:56,946 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:08:58,734 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:09:00,608 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:09:02,188 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:09:03,870 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:09:05,438 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:09:07,267 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-03 11:09:12,945 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 11:09:12,945 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4654 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 11:57:50,468 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-03 11:58:40,716 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 387, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=45)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=45)
2025-10-03 11:58:47,717 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 11:58:52,038 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 12:02:54,101 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 12:02:54,238 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 12:03:03,255 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:03,256 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:03,260 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:03,260 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:05,118 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:05,118 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:05,818 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:05,818 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:06,503 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:06,504 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:07,191 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:07,191 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:08,099 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:08,099 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:08,581 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:08,581 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:09,400 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:09,401 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:10,372 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:10,372 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:11,050 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:11,050 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:11,911 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:11,912 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:12,536 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:12,536 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:13,068 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:13,068 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:13,951 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:13,951 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:14,533 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:14,533 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:15,312 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:15,312 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:16,170 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:16,170 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:17,524 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-10-03 12:03:17,528 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:17,528 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:18,186 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-10-03 12:03:18,211 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:18,211 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:19,100 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-10-03 12:03:20,193 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-10-03 12:03:23,175 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:23,175 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:23,857 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:03:23,857 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:03:25,811 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-10-03 12:03:26,387 [INFO] dash.ai: news._query_llm: provider=DigitalOcean model=llama3-8b-instruct status=200
2025-10-03 12:09:07,156 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 12:09:11,538 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=10 model_pref=local analyze=True
2025-10-03 12:09:14,282 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:09:14,282 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:09:15,861 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:09:15,861 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:09:17,127 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:09:17,127 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:09:18,683 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:09:18,684 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:09:19,195 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 12:09:19,196 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-03 12:09:48,154 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-03 12:10:13,169 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 388, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 12:10:13,174 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 12:10:13,209 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 12:10:33,222 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 388, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 12:20:18,451 [INFO] dash.ai: news.fetch: asset=CRCL days=14 max=10 model_pref=gemini analyze=True
2025-10-03 13:08:50,730 [INFO] dash.ai: news.fetch: asset=NVDA days=14 max=10 model_pref=local analyze=True
2025-10-03 13:09:18,591 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 388, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 13:09:18,661 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 13:09:18,736 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 13:10:16,196 [INFO] dash.ai: news.fetch: asset=NVDA days=14 max=10 model_pref=local analyze=True
2025-10-03 13:10:43,982 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 388, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 13:10:43,988 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 13:10:44,017 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 13:11:10,602 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 388, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:12:09,186 [INFO] dash.ai: news.fetch: asset=META days=14 max=5 model_pref=local analyze=True
2025-10-03 14:12:38,010 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:12:38,024 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 14:12:38,046 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 14:14:12,617 [INFO] dash.ai: news.fetch: asset=AAPL days=14 max=5 model_pref=local analyze=True
2025-10-03 14:14:40,607 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:14:40,621 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 14:14:40,639 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 14:14:41,400 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=deepseek/deepseek-r1-0528-qwen3-8b status=400
2025-10-03 14:14:41,400 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Model unloaded."}
2025-10-03 14:15:31,713 [INFO] dash.ai: news.fetch: asset=META days=14 max=5 model_pref=local analyze=True
2025-10-03 14:15:58,678 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:15:58,683 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 14:15:58,688 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 14:16:18,713 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:41:00,453 [INFO] dash.ai: news.fetch: asset=META days=14 max=5 model_pref=local analyze=True
2025-10-03 14:41:27,002 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:41:27,007 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 14:41:27,013 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 14:41:47,040 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:46:16,691 [INFO] dash.ai: news.fetch: asset=META days=14 max=5 model_pref=local analyze=True
2025-10-03 14:46:46,737 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 14:46:46,745 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 14:47:31,778 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 14:47:51,797 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:05:43,670 [INFO] dash.ai: news.fetch: asset=GOOGL days=14 max=5 model_pref=local analyze=True
2025-10-03 15:06:10,856 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:06:10,862 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 15:06:55,895 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 15:07:16,323 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:28:25,048 [INFO] dash.ai: news.fetch: asset=GOOGL days=14 max=5 model_pref=local analyze=True
2025-10-03 15:28:52,114 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:28:52,190 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 15:29:16,046 [INFO] dash.ai: news.fetch: asset=GOOGL days=14 max=5 model_pref=local analyze=True
2025-10-03 15:29:40,624 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:29:40,630 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 15:30:25,641 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 15:30:45,658 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:54:19,294 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:54:21,183 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 15:54:21,183 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4115 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 15:54:42,992 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:54:48,569 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:54:48,907 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:54:49,089 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:55:02,770 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 15:55:02,770 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4115 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 15:55:02,771 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 15:55:02,799 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 15:55:02,799 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4115 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 15:55:02,799 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 15:55:02,826 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 15:55:02,827 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4115 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-03 15:55:02,827 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 15:56:07,786 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:56:07,817 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:56:07,848 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 15:56:37,629 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:56:46,110 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 15:56:46,110 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Model unloaded."}
2025-10-03 15:56:46,822 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-03 15:56:46,823 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Model unloaded."}
2025-10-03 15:56:47,604 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:56:47,604 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 15:58:32,927 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:58:34,039 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:58:34,273 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 15:58:37,367 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:58:37,367 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 15:58:37,537 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:58:37,537 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 15:58:37,539 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:58:37,539 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 15:58:39,406 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:58:39,406 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 15:58:39,575 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:58:39,575 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 15:58:40,125 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 15:58:40,125 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:01:55,433 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 16:01:55,776 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 16:01:55,950 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-03 16:01:57,595 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 16:01:57,595 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:01:57,634 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:01:57,885 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 16:01:57,886 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:01:57,905 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 16:01:57,906 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:01:59,214 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 16:01:59,214 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:02:00,052 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 16:02:00,052 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:02:00,208 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-03 16:02:00,208 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "No models loaded. Please load a model in the developer page or use the `lms load` command.",
        "type": "invalid_request_error",
        "param": "model",
   
2025-10-03 16:02:10,195 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:02:44,677 [INFO] dash.ai: news.fetch: asset=BTC-USD days=14 max=5 model_pref=local analyze=True
2025-10-03 16:03:12,489 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 16:03:12,505 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 16:03:57,516 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 16:04:17,546 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\.venv\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 16:08:37,474 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:32:13,340 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:32:13,509 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:32:13,641 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:32:23,619 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:32:30,973 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:32:33,779 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:33:17,946 [INFO] dash.ai: news.fetch: asset=MSFT days=14 max=5 model_pref=local analyze=True
2025-10-03 16:33:43,894 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 16:33:43,906 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 16:33:49,693 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:33:59,852 [INFO] dash.ai: news.fetch: asset=MSFT days=14 max=5 model_pref=local analyze=True
2025-10-03 16:34:25,644 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 16:34:25,651 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-03 16:35:10,667 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-03 16:35:30,693 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-03 16:41:00,443 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:41:58,277 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:42:28,019 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:42:33,647 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 16:43:07,162 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 18:10:36,688 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 18:11:18,505 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 18:11:18,728 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-03 18:11:21,730 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=1 model_pref=gemini analyze=True
2025-10-03 18:11:23,698 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=5 model_pref=gemini analyze=True
2025-10-03 18:14:38,749 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=5 model_pref=gemini analyze=True
2025-10-03 18:15:16,568 [INFO] dash.ai: news.fetch: asset=CRCL days=14 max=5 model_pref=local analyze=True
2025-10-03 18:15:40,959 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 18:15:46,151 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 18:15:46,152 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-03 18:15:50,934 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-03 18:17:02,247 [INFO] dash.ai: news.fetch: asset=CRCL days=7 max=5 model_pref=gemini analyze=True
2025-10-13 11:06:59,893 [INFO] dash.ai: news.fetch: asset=NVDA days=14 max=5 model_pref=local analyze=True
2025-10-13 11:07:25,110 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:07:25,225 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-13 11:15:34,291 [INFO] dash.ai: news.fetch: asset=NVDA days=14 max=5 model_pref=local analyze=True
2025-10-13 11:15:58,556 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 11:16:18,558 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:16:18,565 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-13 11:26:23,627 [INFO] dash.ai: news.fetch: asset=NVDA days=14 max=5 model_pref=local analyze=True
2025-10-13 11:26:40,722 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 11:27:00,749 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:27:00,756 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-13 11:27:38,782 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-13 11:27:59,483 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:28:28,874 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:29:21,172 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:30:14,689 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:31:05,214 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:35:28,018 [INFO] dash.ai: news.fetch: asset=AAPL days=14 max=5 model_pref=local analyze=True
2025-10-13 11:35:48,695 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 11:36:08,726 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:36:08,731 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-13 11:36:46,972 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-13 11:37:07,764 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:38:38,290 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:39:35,952 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:40:28,500 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:53:54,020 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-13 11:54:21,824 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:54:21,830 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-13 11:55:04,448 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-13 11:55:24,451 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 292, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\socket.py", line 719, in readinto
    return self._sock.recv_into(b)
           ~~~~~~~~~~~~~~~~~~~~^^^
TimeoutError: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 39, in reraise
    raise value
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 367, in _raise_timeout
    raise ReadTimeoutError(
        self, url, f"Read timed out. (read timeout={timeout_value})"
    ) from err
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 389, in _query_llm
    r = _requests.post(f"{base_url}/chat/completions", headers=headers, json=payload, timeout=20)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 690, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=1234): Read timed out. (read timeout=20)
2025-10-13 11:57:53,460 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:58:50,243 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 11:59:40,765 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 12:05:35,907 [INFO] dash.ai: news.fetch: asset=GOOGL days=14 max=5 model_pref=local analyze=True
2025-10-13 12:06:07,088 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:06:07,088 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-13 12:06:42,476 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:14:34,724 [WARNING] dash.ai: llm_generate: all providers failed
2025-10-13 12:34:23,070 [INFO] dash.ai: news.fetch: asset=AAPL days=14 max=5 model_pref=local analyze=True
2025-10-13 12:34:39,763 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:34:42,042 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:34:45,171 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:34:51,864 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:34:51,864 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 4 items
2025-10-13 12:34:55,778 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:55:09,987 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-13 12:55:10,292 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-13 12:55:42,364 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-13 12:55:49,461 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:55:51,175 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:55:54,413 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:55:59,321 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:56:06,804 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-13 12:56:11,982 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen2.5-7b-instruct status=200
2025-10-14 10:46:24,989 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-14 10:46:31,328 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:46:31,328 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4154 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:47:39,457 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 10:47:39,457 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 10:47:39,910 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:47:39,910 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4156 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:47:47,517 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-14 10:47:47,881 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-14 10:47:53,422 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:47:53,422 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4154 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:47:54,225 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:47:54,225 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4154 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:48:56,844 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 10:48:56,844 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 10:48:57,325 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 10:48:57,325 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen2.5-7b-instruct\nqwen/qwen3-4b-thinking-2507\ndeepseek/deepseek-r1-052
2025-10-14 10:49:24,723 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:49:24,723 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Model unloaded."}
2025-10-14 10:49:24,723 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-14 10:49:38,443 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 10:49:38,913 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:49:38,913 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4196 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:50:00,313 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=5 model_pref=local analyze=True
2025-10-14 10:50:05,717 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:50:05,717 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4154 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:51:12,382 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 10:51:12,383 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 10:51:12,815 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 10:51:12,815 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4115 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 10:52:55,126 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-14 10:52:56,080 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-14 10:53:11,337 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-14 10:53:21,389 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=gemini analyze=True
2025-10-14 10:53:51,893 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 10:54:43,924 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 10:55:59,653 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-14 10:56:56,640 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 10:58:36,155 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 10:59:01,433 [INFO] dash.ai: news.fetch: asset=BTC days=7 max=1 model_pref=local analyze=True
2025-10-14 10:59:08,329 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 11:00:19,182 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-10-14 11:00:43,876 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:01:47,394 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:04:53,643 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-10-14 11:05:04,640 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-10-14 11:05:30,957 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:05:40,438 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-10-14 11:05:41,021 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-10-14 11:05:45,007 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=1 model_pref=local analyze=True
2025-10-14 11:05:48,797 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 11:05:48,798 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 11:05:48,798 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 11:06:55,456 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:07:05,210 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 11:07:05,210 [ERROR] dash.ai: news._query_llm exception (Local OpenAI-Compat): ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\urllib3\connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\http\client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Jobbie\c++Workspace\Comp301 project\dash\services.py", line 419, in _query_llm
    r = _requests.post(
        f"{base_url}/chat/completions",
    ...<2 lines>...
        timeout=_LLM_HTTP_TIMEOUT,
    )
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Jobbie\AppData\Local\Programs\Python\Python313\Lib\site-packages\requests\adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2025-10-14 11:08:23,210 [INFO] dash.ai: news.fetch: asset=ETH days=7 max=5 model_pref=local analyze=True
2025-10-14 11:09:11,247 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:09:11,248 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-14 11:09:11,321 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:09:11,321 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4565 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:14:58,394 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:15:06,554 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:15:13,399 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:15:13,399 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4138 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:15:34,870 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:15:34,870 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 11:15:34,952 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:15:34,952 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5226 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:15:41,120 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:15:47,861 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:15:47,861 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4141 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:16:21,483 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:16:27,359 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:16:27,359 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4141 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:16:27,523 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:16:49,042 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:16:49,043 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 11:16:49,076 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:16:49,077 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4141 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:16:49,077 [INFO] dash.ai: news.fetch: per-article budget exceeded for provider=gemini
2025-10-14 11:16:49,127 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:16:49,128 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5125 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:16:54,525 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-14 11:16:54,594 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:16:54,594 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5447 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:20:04,265 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=1 model_pref=local analyze=True
2025-10-14 11:20:05,947 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:20:05,947 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4141 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:21:36,901 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:36:51,387 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:36:59,400 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:36:59,400 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4152 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:37:28,088 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:37:28,088 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 11:37:28,165 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:37:28,165 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5174 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:39:39,864 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:39:48,517 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:39:48,517 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4152 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:40:13,867 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:40:13,868 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 2 items
2025-10-14 11:40:13,917 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:40:13,917 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5170 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:42:34,705 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:43:45,100 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:43:45,100 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-14 11:43:45,156 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:43:45,156 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5462 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:43:58,686 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:44:02,390 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:44:57,200 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:44:57,201 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-14 11:45:54,560 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:45:54,560 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 1 items
2025-10-14 11:45:54,604 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:45:54,605 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5413 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:45:54,642 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:45:54,642 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 5460 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 11:51:15,141 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 11:51:22,411 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 11:51:22,411 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen/qwen3-4b-thinking-2507\nqwen2.5-7b-instruct\ntext-embedding-nomic-emb
2025-10-14 11:51:23,930 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 11:51:23,930 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen/qwen3-4b-thinking-2507\nqwen2.5-7b-instruct\ntext-embedding-nomic-emb
2025-10-14 11:51:25,091 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 11:51:25,092 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen/qwen3-4b-thinking-2507\nqwen2.5-7b-instruct\ntext-embedding-nomic-emb
2025-10-14 11:51:26,563 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 11:51:26,563 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen/qwen3-4b-thinking-2507\nqwen2.5-7b-instruct\ntext-embedding-nomic-emb
2025-10-14 11:51:27,645 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 11:51:27,645 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen/qwen3-4b-thinking-2507\nqwen2.5-7b-instruct\ntext-embedding-nomic-emb
2025-10-14 11:51:29,692 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=404
2025-10-14 11:51:29,692 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {
    "error": {
        "message": "Model \"gpt-4o-mini-compat\" not found. Please specify a valid model.\n\nYour models:\n\nqwen/qwen3-4b-thinking-2507\nqwen2.5-7b-instruct\ntext-embedding-nomic-emb
2025-10-14 11:54:12,319 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=1 model_pref=local analyze=True
2025-10-14 11:54:24,965 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:54:34,352 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:54:48,129 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=local analyze=True
2025-10-14 11:55:01,649 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:55:05,349 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:55:09,234 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:55:18,704 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 11:55:18,769 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 11:55:18,769 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4427 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 12:26:04,457 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=local analyze=True
2025-10-14 12:26:17,988 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:26:19,920 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:26:23,188 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:26:32,272 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:26:36,324 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:26:36,367 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 12:26:36,367 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4349 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 12:58:31,314 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=local analyze=True
2025-10-14 12:58:36,406 [INFO] dash.ai: news.fetch: asset=BTC days=1 max=5 model_pref=local analyze=True
2025-10-14 12:58:44,126 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:58:46,243 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:58:50,580 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:58:52,704 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:59:01,941 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:59:01,941 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 3 items
2025-10-14 12:59:04,013 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 12:59:04,014 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 3 items
2025-10-14 12:59:04,050 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 12:59:04,050 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4550 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 12:59:04,084 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 12:59:04,085 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4615 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
2025-10-14 13:03:25,625 [INFO] dash.ai: news.fetch: asset=AMD days=14 max=5 model_pref=local analyze=True
2025-10-14 13:03:50,056 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen/qwen3-4b-2507 status=200
2025-10-14 13:03:51,546 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen/qwen3-4b-2507 status=200
2025-10-14 13:03:53,128 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen/qwen3-4b-2507 status=200
2025-10-14 13:03:56,510 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen/qwen3-4b-2507 status=200
2025-10-14 13:04:00,432 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen/qwen3-4b-2507 status=200
2025-10-14 13:04:07,563 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=qwen/qwen3-4b-2507 status=200
2025-10-14 13:15:10,460 [INFO] dash.ai: news.fetch: asset=ETH days=1 max=5 model_pref=local analyze=True
2025-10-14 13:15:22,050 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 13:15:31,041 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 13:15:35,018 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 13:15:44,403 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=200
2025-10-14 13:15:44,403 [WARNING] dash.ai: news.fetch: total analysis budget exceeded; stopping at 4 items
2025-10-14 13:15:44,467 [INFO] dash.ai: news._query_llm: provider=Local OpenAI-Compat model=gpt-4o-mini-compat status=400
2025-10-14 13:15:44,467 [WARNING] dash.ai: news._query_llm error (Local OpenAI-Compat): {"error":"Trying to keep the first 4404 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a large
